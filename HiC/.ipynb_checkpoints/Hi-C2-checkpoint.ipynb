{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task:\n",
    "we need to map a peak to one chunk in the bed file, and then see if the other chunk in contact with it is the promoter of any gene. The difference from Hi-C.ipynb is the gene annotation file is provided by Jubao. Also, when we test whether a fragment intersects with a promoter, if the fragment size is less than 5 kb, we expand it equally to both size so that the total length is 5kb.\n",
    "\n",
    "* SNP to peak definition:  \n",
    "+/- 250bp of peak region\n",
    "\n",
    "* promoter definition:  \n",
    "2kb upstream and 1kb downstream of gene TSS \n",
    "\n",
    "* in contact definition:  \n",
    "each row in the Hi-C file defines in contact.\n",
    "\n",
    "* peak-HiC and promoter-HiC contact\n",
    "20% overlap of peak size between peak and hic, 20% overlap of promoter size between promoter and hic. if the fragment size is less than 5 kb, we expand it equally to both size so that the total length is 5kb.\n",
    "\n",
    "## format:\n",
    "* Hi-C files  \n",
    "\n",
    "    * [PsychEncode data](https://science.sciencemag.org/content/362/6420/eaat4311), obtained from Siwei, in hg19, a Hi-C bed file with the name XXX.50000_blocks.bed, each number A in the 2nd/3rd column represents a fragment that spans from A to A+50000.\n",
    "    * [Nature 2016](https://www.nature.com/articles/nature19847)\n",
    "    * [NG 2019](http://dx.doi.org/10.1038/s41588-019-0472-1),\n",
    "    in hg19,\n",
    "    `wget https://static-content.springer.com/esm/art%3A10.1038%2Fs41588-019-0472-1/MediaObjects/41588_2019_472_MOESM4_ESM.xlsx`\n",
    "\n",
    "\n",
    "* ASoC SNP file  \n",
    "in hg38. from Yifan.\n",
    "\n",
    "* peak file  \n",
    "in hg38. CN means glutamatergic neurons, and I guess we should use Hi-C files starting with 'Neu';\n",
    "NSC means neural progenitor cells, and I guess we should use Hi-C files starting with 'NPC'. from Yifan.\n",
    "\n",
    "* gene anno file  \n",
    "in hg19. `GENCODE_V31lift37_Duan.dms` from Jubao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project2/xinhe/simingz/neuron_atac_seq/HiC\n"
     ]
    }
   ],
   "source": [
    "cd /project2/xinhe/simingz/neuron_atac_seq/HiC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybedtools\n",
    "from pyliftover import LiftOver\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import subprocess\n",
    "import os\n",
    "from functools import reduce\n",
    "from brokenaxes import brokenaxes\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snp2gene(snpf, peakf, hicf, annof, outtag):\n",
    "    '''snp to peak to gene promoter\n",
    "    '''\n",
    "    # snp to peak\n",
    "    peakflsize = 250\n",
    "    snps = pybedtools.BedTool(snpf)\n",
    "    peaks = pybedtools.BedTool(peakf)\n",
    "    peaksfl = peaks.slop(genome = 'hg38', b = peakflsize)\n",
    "    snp2peak = snps.intersect(peaksfl, wb=True)\n",
    "    snp2peak.saveas(outtag + '.snp2peak.bed')  \n",
    "    \n",
    "    # snp2peak liftover\n",
    "    lo = LiftOver('hg38', 'hg19')\n",
    "    with open(outtag + '.snp2peak.lo.bed', 'w') as snp2peaklo:\n",
    "        for snp in snp2peak:\n",
    "            s = lo.convert_coordinate(snp.fields[8], int(snp.fields[9]))\n",
    "            e = lo.convert_coordinate(snp.fields[8], int(snp.fields[10]))\n",
    "            if len(s) !=0 and len(e) != 0:\n",
    "                if s[0][0] == e[0][0] and s[0][1] < e[0][1]:\n",
    "                    peaklo = [s[0][0], str(s[0][1]), str(e[0][1])]\n",
    "                    snp2peaklo.write('\\t'.join(peaklo + list(snp)) + '\\n')\n",
    "    \n",
    "    # annotate with HiC contact\n",
    "    hics = pybedtools.BedTool(hicf)\n",
    "    snppeak = pybedtools.BedTool(outtag + '.snp2peak.lo.bed')\n",
    "    snppeakhic = snppeak.intersect(hics, wao=True)\n",
    "    snppeakhic.saveas(outtag + '.snp2peak.lo.hic1.bed')\n",
    "    \n",
    "    # annotate the other end with promoter info\n",
    "    snppeakhic1 = pybedtools.BedTool([[i[14]] + i[17:19] + i[0:17] + [i[19]] for i in snppeakhic if i[19]!='0'])\n",
    "    annos= pybedtools.BedTool(annof)\n",
    "    snppeakhic2 = snppeakhic1.intersect(annos, wao= True)\n",
    "    snppeakhic2.saveas(outtag + '.snp2peak.lo.hic2.bed')\n",
    "    out = pybedtools.BedTool([i for i in snppeakhic2 if i[25] != '0'])\n",
    "    out2 = list(set(['\\t'.join(outr[6:17] + outr[24:27]) for outr in out]))\n",
    "    \n",
    "    # write output\n",
    "    with open(outtag + '.bed', 'w') as outfile:\n",
    "        # outfile.write('\\t'.join(['SNP.chr','SNP.start','SNP.end','SNP.label','SNP','SNP','SNP','SNP', 'peak.chr', 'peak.start', 'peak.end', 'geneID1','geneID2','geneID3']) +'\\n')\n",
    "        for outr in out2:\n",
    "            outfile.write(outr + '\\n')\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promoter annotation file, need manually remove unwanted chroms\n",
    "awk -F'\\t' '{print $0}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NG 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HiC further process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t876092\t889423\t1206874\t1212438\n",
      "chr1\t889424\t903640\t927395\t936954\n",
      "chr1\t903641\t927394\t936955\t942417\n",
      "chr1\t903641\t927394\t978382\t989620\n",
      "chr1\t903641\t927394\t1206874\t1212438\n",
      "chr1\t927395\t936954\t942418\t943676\n",
      "chr1\t927395\t936954\t943677\t957199\n",
      "chr1\t927395\t936954\t1069046\t1083958\n",
      "chr1\t927395\t936954\t1083959\t1091234\n",
      "chr1\t927395\t936954\t1109733\t1122642\n"
     ]
    }
   ],
   "source": [
    "!head NG2019-HiC-hippo.converted.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend to 5kb\n",
    "def To5kb(hicf, outf):\n",
    "    with open(hicf) as f1, open(outf,'w') as f2:\n",
    "        csvreader = csv.reader(f1, delimiter = '\\t')\n",
    "        csvwriter = csv.writer(f2, delimiter = '\\t', lineterminator=os.linesep)\n",
    "        for row in csvreader:\n",
    "            if int(row[2]) -int(row[1]) < 5000:\n",
    "                mid = round(0.5 * (int(row[1]) + int(row[2])))\n",
    "                row[1] = str(mid - 2500)\n",
    "                row[2] = str(mid + 2500)\n",
    "            if int(row[4]) -int(row[3]) < 5000:\n",
    "                mid = round(0.5 * (int(row[3]) + int(row[4])))\n",
    "                row[3] = str(mid - 2500)\n",
    "                row[4] = str(mid + 2500)\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "To5kb('NG2019-HiC-hippo.converted.bed', 'NG2019-HiC-hippo.converted5kb.bed')\n",
    "To5kb('NG2019-HiC-ex.converted.bed', 'NG2019-HiC-ex.converted5kb.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t876091\t889423\t1206873\t1212438\n",
      "chr1\t889423\t903640\t927394\t936954\n",
      "chr1\t903640\t927394\t936954\t942417\n",
      "chr1\t903640\t927394\t978381\t989620\n",
      "chr1\t903640\t927394\t1206873\t1212438\n",
      "chr1\t927394\t936954\t940546\t945546\n",
      "chr1\t927394\t936954\t943676\t957199\n",
      "chr1\t927394\t936954\t1069045\t1083958\n",
      "chr1\t927394\t936954\t1083958\t1091234\n",
      "chr1\t927394\t936954\t1109732\t1122642\n"
     ]
    }
   ],
   "source": [
    "!head NG2019-HiC-hippo.converted5kb.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge HiC and eQTL results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge HiC and eQTL results into a single table, each row is one ASoC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eID2gene(eids):\n",
    "    geneList = [i.split('.')[0] for i in eids.split(',')]\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    geneSyms = mg.querymany(geneList , scopes='ensembl.gene', fields='symbol', species='human')\n",
    "    try:\n",
    "        gene = [i['symbol'] for i in geneSyms]\n",
    "    except KeyError:\n",
    "        gene=[]\n",
    "    geneout = ','.join(gene)\n",
    "    return(geneout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpf = 'CN_20_ASoC_FDR0.05.bed'\n",
    "peakf = 'CN_merged_all_20_peaks.hotspot.bed'\n",
    "hicf = 'NG2019-HiC-hippo.converted5kb.bed'\n",
    "annof = 'GENCODE_V31lift37_Duan.dms.promoter.bed'\n",
    "outtag = 'CN.hic-ng2019-hippo2'\n",
    "out = snp2gene(snpf, peakf, hicf, annof, outtag)\n",
    "hicf = 'NG2019-HiC-ex.converted5kb.bed'\n",
    "outtag = 'CN.hic-ng2019-ex2'\n",
    "out = snp2gene(snpf, peakf, hicf, annof, outtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(CN_20_ASoC_FDR0.05_promotor2.bed.hg19)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snpflo = 'CN_20_ASoC_FDR0.05.bed.hg19'\n",
    "snps = pybedtools.BedTool(snpflo)\n",
    "annos= pybedtools.BedTool(annof)\n",
    "snppro = snps.intersect(annos, wb=True)\n",
    "snppro.sort().merge(c=\"4,12,13,14\", o=\"distinct\").saveas('CN_20_ASoC_FDR0.05_promotor2.bed.hg19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join\n",
    "f1 = pd.read_csv(snpf, delimiter= '\\t', header= None)\n",
    "f1snp = f1.iloc[:,0:4]\n",
    "f1snp.columns = ['chrom', 'snp.start', 'snp.end', 'rsID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = pd.read_csv('CN_20_ASoC_FDR0.05_promotor2.bed.hg19', delimiter= '\\t', header= None)\n",
    "f2 = f2.iloc[:,3:7]\n",
    "f2.columns = ['rsID','promoter_transcriptID', 'promoter_geneID', 'promoter_gene_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtlf = '../eQTL/CN_ASoC_500kb_0.05_CMC_eQTLanno.bed'\n",
    "f3 = pd.read_csv(eqtlf + '.hg38', delimiter= '\\t', header= None)\n",
    "f3.columns = ['chrom', 'snp.end', 'eQTL_geneID']\n",
    "f3['eQTL_gene_symbol'] = f3['eQTL_geneID'].apply(eID2gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = pd.read_csv('CN.hic-ng2019-ex2.bed', delimiter= '\\t', header= None)\n",
    "f4ex1 = f4.groupby([3])[11].apply(','.join).reset_index()\n",
    "f4ex1.columns = ['rsID','excitatory_HiC_transcriptID']\n",
    "f4ex2 = f4.groupby([3])[12].apply(','.join).reset_index()\n",
    "f4ex2.columns = ['rsID','excitatory_HiC_geneID'] \n",
    "f4ex3 = f4.groupby([3])[13].apply(','.join).reset_index()\n",
    "f4ex3.columns = ['rsID','excitatory_HiC_gene_symbol'] \n",
    "f4ex12 = pd.merge(f4ex1,f4ex2,left_on=['rsID'], right_on = ['rsID'])\n",
    "f4ex = pd.merge(f4ex12,f4ex3,left_on=['rsID'], right_on = ['rsID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "f5 = pd.read_csv('CN.hic-ng2019-hippo2.bed', delimiter= '\\t', header= None)\n",
    "f5hippo1 = f5.groupby([3])[11].apply(','.join).reset_index()\n",
    "f5hippo1.columns = ['rsID','hippocampus_HiC_transcriptID']\n",
    "f5hippo2 = f5.groupby([3])[12].apply(','.join).reset_index()\n",
    "f5hippo2.columns = ['rsID','hippocampus_HiC_geneID'] \n",
    "f5hippo3 = f5.groupby([3])[13].apply(','.join).reset_index()\n",
    "f5hippo3.columns = ['rsID','hippocampus_HiC_gene_symbol'] \n",
    "f5hippo12 = pd.merge(f5hippo1,f5hippo2,left_on=['rsID'], right_on = ['rsID'])\n",
    "f5hippo = pd.merge(f5hippo12,f5hippo3,left_on=['rsID'], right_on = ['rsID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1f2 = pd.merge(f1snp, f2,  how='left', left_on=['rsID'], right_on = ['rsID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1f2f3 = pd.merge(f1f2, f3, how='left', left_on=['chrom', 'snp.end'], right_on = ['chrom','snp.end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_merged = reduce(lambda left,right: pd.merge(left,right,on=['rsID'],\n",
    "                                            how='left'), [f1f2f3,f4ex,f5hippo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_merged.fillna('-').to_csv('CN_20_ASoC_FDR0.05_eQTL_HiC2.txt',sep = '\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpf = 'NSC_20_ASoC_FDR0.05.bed'\n",
    "peakf = 'NSC_merged_all_20_peaks.hotspot.bed'\n",
    "hicf = 'NG2019-HiC-hippo.converted5kb.bed'\n",
    "annof = 'GENCODE_V31lift37_Duan.dms.promoter.bed'\n",
    "outtag = 'NSC.hic-ng2019-hippo2'\n",
    "out = snp2gene(snpf, peakf, hicf, annof, outtag)\n",
    "hicf = 'NG2019-HiC-ex.converted5kb.bed'\n",
    "outtag = 'NSC.hic-ng2019-ex2'\n",
    "out = snp2gene(snpf, peakf, hicf, annof, outtag)\n",
    "\n",
    "snpflo = 'NSC_20_ASoC_FDR0.05.bed.hg19'\n",
    "snps = pybedtools.BedTool(snpflo)\n",
    "annos= pybedtools.BedTool(annof)\n",
    "snppro = snps.intersect(annos, wb=True)\n",
    "snppro.sort().merge(c=\"4,12,13,14\", o=\"distinct\").saveas('NSC_20_ASoC_FDR0.05_promotor2.bed.hg19')\n",
    "\n",
    "# join\n",
    "f1 = pd.read_csv(snpf, delimiter= '\\t', header= None)\n",
    "f1snp = f1.iloc[:,0:4]\n",
    "f1snp.columns = ['chrom', 'snp.start', 'snp.end', 'rsID']\n",
    "\n",
    "f2 = pd.read_csv('NSC_20_ASoC_FDR0.05_promotor2.bed.hg19', delimiter= '\\t', header= None)\n",
    "f2 = f2.iloc[:,3:7]\n",
    "f2.columns = ['rsID','promoter_transcriptID', 'promoter_geneID', 'promoter_gene_symbol']\n",
    "\n",
    "eqtlf = '../eQTL/NSC_ASoC_500kb_0.05_CMC_eQTLanno.bed'\n",
    "f3 = pd.read_csv(eqtlf + '.hg38', delimiter= '\\t', header= None)\n",
    "f3.columns = ['chrom', 'snp.end', 'eQTL_geneID']\n",
    "f3['eQTL_gene_symbol'] = f3['eQTL_geneID'].apply(eID2gene)\n",
    "\n",
    "f4 = pd.read_csv('NSC.hic-ng2019-ex2.bed', delimiter= '\\t', header= None)\n",
    "f4ex1 = f4.groupby([3])[11].apply(','.join).reset_index()\n",
    "f4ex1.columns = ['rsID','excitatory_HiC_transcriptID']\n",
    "f4ex2 = f4.groupby([3])[12].apply(','.join).reset_index()\n",
    "f4ex2.columns = ['rsID','excitatory_HiC_geneID'] \n",
    "f4ex3 = f4.groupby([3])[13].apply(','.join).reset_index()\n",
    "f4ex3.columns = ['rsID','excitatory_HiC_gene_symbol'] \n",
    "f4ex12 = pd.merge(f4ex1,f4ex2,left_on=['rsID'], right_on = ['rsID'])\n",
    "f4ex = pd.merge(f4ex12,f4ex3,left_on=['rsID'], right_on = ['rsID'])\n",
    "\n",
    "f5 = pd.read_csv('NSC.hic-ng2019-hippo2.bed', delimiter= '\\t', header= None)\n",
    "f5hippo1 = f5.groupby([3])[11].apply(','.join).reset_index()\n",
    "f5hippo1.columns = ['rsID','hippocampus_HiC_transcriptID']\n",
    "f5hippo2 = f5.groupby([3])[12].apply(','.join).reset_index()\n",
    "f5hippo2.columns = ['rsID','hippocampus_HiC_geneID'] \n",
    "f5hippo3 = f5.groupby([3])[13].apply(','.join).reset_index()\n",
    "f5hippo3.columns = ['rsID','hippocampus_HiC_gene_symbol'] \n",
    "f5hippo12 = pd.merge(f5hippo1,f5hippo2,left_on=['rsID'], right_on = ['rsID'])\n",
    "f5hippo = pd.merge(f5hippo12,f5hippo3,left_on=['rsID'], right_on = ['rsID'])\n",
    "\n",
    "f1f2 = pd.merge(f1snp, f2,  how='left', left_on=['rsID'], right_on = ['rsID'])\n",
    "\n",
    "f1f2f3 = pd.merge(f1f2, f3, how='left', left_on=['chrom', 'snp.end'], right_on = ['chrom','snp.end'])\n",
    "\n",
    "f_merged = reduce(lambda left,right: pd.merge(left,right,on=['rsID'],\n",
    "                                            how='left'), [f1f2f3,f4ex,f5hippo])\n",
    "\n",
    "f_merged.fillna('-').to_csv('NSC_20_ASoC_FDR0.05_eQTL_HiC2.txt',sep = '\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(NSC_20_ASoC_FDR0.05_promotor2.bed.hg19)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snpf = 'NSC_20_ASoC_FDR0.05.bed'\n",
    "peakf = 'NSC_merged_all_20_peaks.hotspot.bed'\n",
    "hicf = 'NG2019-HiC-hippo.converted5kb.bed'\n",
    "annof = 'GENCODE_V31lift37_Duan.dms.promoter.bed'\n",
    "outtag = 'NSC.hic-ng2019-hippo2'\n",
    "out = snp2gene(snpf, peakf, hicf, annof, outtag)\n",
    "hicf = 'NG2019-HiC-ex.converted5kb.bed'\n",
    "outtag = 'NSC.hic-ng2019-ex2'\n",
    "out = snp2gene(snpf, peakf, hicf, annof, outtag)\n",
    "\n",
    "snpflo = 'NSC_20_ASoC_FDR0.05.bed.hg19'\n",
    "snps = pybedtools.BedTool(snpflo)\n",
    "annos= pybedtools.BedTool(annof)\n",
    "snppro = snps.intersect(annos, wb=True)\n",
    "snppro.sort().merge(c=\"4,12,13,14\", o=\"distinct\").saveas('NSC_20_ASoC_FDR0.05_promotor2.bed.hg19')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:testotherpy3]",
   "language": "python",
   "name": "conda-env-testotherpy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
